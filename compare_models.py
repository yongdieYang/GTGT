import torch
import numpy as np
from collections import OrderedDict
import os

def compare_model_files(model_path1, model_path2, tolerance=1e-8):
    """
    å¯¹æ¯”ä¸¤ä¸ªPyTorchæ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œå…¨ä¸€è‡´
    
    Args:
        model_path1 (str): ç¬¬ä¸€ä¸ªæ¨¡å‹æ–‡ä»¶è·¯å¾„
        model_path2 (str): ç¬¬äºŒä¸ªæ¨¡å‹æ–‡ä»¶è·¯å¾„
        tolerance (float): æµ®ç‚¹æ•°æ¯”è¾ƒçš„å®¹å·®å€¼
    
    Returns:
        dict: åŒ…å«è¯¦ç»†æ¯”è¾ƒç»“æœçš„å­—å…¸
    """
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path1):
        return {"error": f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path1}"}
    if not os.path.exists(model_path2):
        return {"error": f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path2}"}
    
    try:
        # åŠ è½½æ¨¡å‹
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path1}")
        model1 = torch.load(model_path1, map_location='cpu')
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path2}")
        model2 = torch.load(model_path2, map_location='cpu')
        
        result = {
            "files_identical": True,
            "details": {},
            "differences": []
        }
        
        # 1. æ¯”è¾ƒæ–‡ä»¶å¤§å°
        size1 = os.path.getsize(model_path1)
        size2 = os.path.getsize(model_path2)
        result["details"]["file_sizes"] = {"model1": size1, "model2": size2}
        
        if size1 != size2:
            result["files_identical"] = False
            result["differences"].append(f"æ–‡ä»¶å¤§å°ä¸åŒ: {size1} vs {size2} bytes")
        
        # 2. æ¯”è¾ƒé¡¶å±‚é”®
        keys1 = set(model1.keys()) if isinstance(model1, dict) else set()
        keys2 = set(model2.keys()) if isinstance(model2, dict) else set()
        
        result["details"]["keys"] = {
            "model1_keys": sorted(list(keys1)),
            "model2_keys": sorted(list(keys2))
        }
        
        if keys1 != keys2:
            result["files_identical"] = False
            missing_in_2 = keys1 - keys2
            missing_in_1 = keys2 - keys1
            if missing_in_2:
                result["differences"].append(f"æ¨¡å‹2ä¸­ç¼ºå°‘çš„é”®: {missing_in_2}")
            if missing_in_1:
                result["differences"].append(f"æ¨¡å‹1ä¸­ç¼ºå°‘çš„é”®: {missing_in_1}")
        
        # 3. æ¯”è¾ƒå…±åŒçš„é”®
        common_keys = keys1 & keys2
        for key in common_keys:
            print(f"æ­£åœ¨æ¯”è¾ƒé”®: {key}")
            
            val1 = model1[key]
            val2 = model2[key]
            
            # æ¯”è¾ƒå¼ é‡
            if isinstance(val1, torch.Tensor) and isinstance(val2, torch.Tensor):
                if not compare_tensors(val1, val2, tolerance):
                    result["files_identical"] = False
                    result["differences"].append(f"å¼ é‡ '{key}' ä¸åŒ")
                    result["details"][f"{key}_shape"] = {"model1": val1.shape, "model2": val2.shape}
                    if val1.shape == val2.shape:
                        diff = torch.abs(val1 - val2)
                        max_diff = torch.max(diff).item()
                        result["details"][f"{key}_max_diff"] = max_diff
            
            # æ¯”è¾ƒå­—å…¸ï¼ˆå¦‚state_dictï¼‰
            elif isinstance(val1, dict) and isinstance(val2, dict):
                dict_result = compare_state_dicts(val1, val2, tolerance)
                if not dict_result["identical"]:
                    result["files_identical"] = False
                    result["differences"].extend([f"åœ¨ '{key}' ä¸­: {diff}" for diff in dict_result["differences"]])
                    result["details"][f"{key}_comparison"] = dict_result
            
            # æ¯”è¾ƒå…¶ä»–ç±»å‹
            else:
                if val1 != val2:
                    result["files_identical"] = False
                    result["differences"].append(f"é”® '{key}' çš„å€¼ä¸åŒ: {val1} vs {val2}")
        
        return result
        
    except Exception as e:
        return {"error": f"åŠ è½½æˆ–æ¯”è¾ƒæ¨¡å‹æ—¶å‡ºé”™: {str(e)}"}

def compare_tensors(tensor1, tensor2, tolerance=1e-8):
    """
    æ¯”è¾ƒä¸¤ä¸ªå¼ é‡æ˜¯å¦ç›¸ç­‰
    """
    if tensor1.shape != tensor2.shape:
        return False
    
    if tensor1.dtype != tensor2.dtype:
        return False
    
    # ä½¿ç”¨torch.allcloseè¿›è¡Œæ•°å€¼æ¯”è¾ƒ
    return torch.allclose(tensor1, tensor2, atol=tolerance, rtol=tolerance)

def compare_state_dicts(state_dict1, state_dict2, tolerance=1e-8):
    """
    æ¯”è¾ƒä¸¤ä¸ªstate_dict
    """
    result = {
        "identical": True,
        "differences": [],
        "parameter_count": {"model1": len(state_dict1), "model2": len(state_dict2)}
    }
    
    keys1 = set(state_dict1.keys())
    keys2 = set(state_dict2.keys())
    
    if keys1 != keys2:
        result["identical"] = False
        missing_in_2 = keys1 - keys2
        missing_in_1 = keys2 - keys1
        if missing_in_2:
            result["differences"].append(f"å‚æ•°ç¼ºå¤±åœ¨æ¨¡å‹2: {missing_in_2}")
        if missing_in_1:
            result["differences"].append(f"å‚æ•°ç¼ºå¤±åœ¨æ¨¡å‹1: {missing_in_1}")
    
    # æ¯”è¾ƒå…±åŒå‚æ•°
    common_keys = keys1 & keys2
    total_params = 0
    different_params = 0
    
    for key in common_keys:
        param1 = state_dict1[key]
        param2 = state_dict2[key]
        
        if isinstance(param1, torch.Tensor) and isinstance(param2, torch.Tensor):
            total_params += param1.numel()
            if not compare_tensors(param1, param2, tolerance):
                result["identical"] = False
                different_params += param1.numel()
                result["differences"].append(f"å‚æ•° '{key}' ä¸åŒ (shape: {param1.shape})")
        else:
            if param1 != param2:
                result["identical"] = False
                result["differences"].append(f"éå¼ é‡å‚æ•° '{key}' ä¸åŒ")
    
    result["parameter_stats"] = {
        "total_parameters": total_params,
        "different_parameters": different_params,
        "similarity_percentage": (total_params - different_params) / total_params * 100 if total_params > 0 else 100
    }
    
    return result

def print_comparison_report(result):
    """
    æ‰“å°è¯¦ç»†çš„æ¯”è¾ƒæŠ¥å‘Š
    """
    if "error" in result:
        print(f"âŒ é”™è¯¯: {result['error']}")
        return
    
    print("\n" + "="*60)
    print("           PyTorch æ¨¡å‹æ¯”è¾ƒæŠ¥å‘Š")
    print("="*60)
    
    if result["files_identical"]:
        print("âœ… ç»“æœ: ä¸¤ä¸ªæ¨¡å‹æ–‡ä»¶å®Œå…¨ä¸€è‡´!")
    else:
        print("âŒ ç»“æœ: ä¸¤ä¸ªæ¨¡å‹æ–‡ä»¶å­˜åœ¨å·®å¼‚!")
    
    print(f"\nğŸ“Š æ–‡ä»¶å¤§å°:")
    sizes = result["details"].get("file_sizes", {})
    print(f"   æ¨¡å‹1: {sizes.get('model1', 'N/A')} bytes")
    print(f"   æ¨¡å‹2: {sizes.get('model2', 'N/A')} bytes")
    
    if "keys" in result["details"]:
        keys_info = result["details"]["keys"]
        print(f"\nğŸ”‘ é¡¶å±‚é”®:")
        print(f"   æ¨¡å‹1: {keys_info['model1_keys']}")
        print(f"   æ¨¡å‹2: {keys_info['model2_keys']}")
    
    if result["differences"]:
        print(f"\nâš ï¸  å‘ç°çš„å·®å¼‚ ({len(result['differences'])} é¡¹):")
        for i, diff in enumerate(result["differences"], 1):
            print(f"   {i}. {diff}")
    
    # æ˜¾ç¤ºå‚æ•°ç»Ÿè®¡ä¿¡æ¯
    for key, value in result["details"].items():
        if key.endswith("_comparison") and isinstance(value, dict):
            if "parameter_stats" in value:
                stats = value["parameter_stats"]
                print(f"\nğŸ“ˆ {key.replace('_comparison', '')} å‚æ•°ç»Ÿè®¡:")
                print(f"   æ€»å‚æ•°æ•°: {stats['total_parameters']:,}")
                print(f"   ä¸åŒå‚æ•°æ•°: {stats['different_parameters']:,}")
                print(f"   ç›¸ä¼¼åº¦: {stats['similarity_percentage']:.2f}%")
    
    print("\n" + "="*60)

def main():
    """
    ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•
    """
    # ç¤ºä¾‹ï¼šæ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹æ–‡ä»¶
    model1_path = "final_best_model_clean.pth"
    model2_path = "model_186.pth"
    
    print("PyTorch æ¨¡å‹æ¯”è¾ƒå·¥å…·")
    print(f"æ¯”è¾ƒæ¨¡å‹: {model1_path} vs {model2_path}")
    
    # æ‰§è¡Œæ¯”è¾ƒ
    result = compare_model_files(model1_path, model2_path, tolerance=1e-8)
    
    # æ‰“å°æŠ¥å‘Š
    print_comparison_report(result)
    
    # å¯é€‰ï¼šä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶
    import json
    with open("model_comparison_result.json", "w", encoding="utf-8") as f:
        # å¤„ç†ä¸èƒ½åºåˆ—åŒ–çš„å¯¹è±¡
        serializable_result = {}
        for k, v in result.items():
            if isinstance(v, (str, int, float, bool, list)):
                serializable_result[k] = v
            elif isinstance(v, dict):
                serializable_result[k] = {}
                for k2, v2 in v.items():
                    if isinstance(v2, (str, int, float, bool, list, dict)):
                        serializable_result[k][k2] = v2
                    else:
                        serializable_result[k][k2] = str(v2)
            else:
                serializable_result[k] = str(v)
        
        json.dump(serializable_result, f, ensure_ascii=False, indent=2)
    
    print("\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: model_comparison_result.json")

if __name__ == "__main__":
    main()